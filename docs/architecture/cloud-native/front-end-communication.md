---
title: Взаимодействие с внешними клиентами
description: Узнайте, как клиентские клиенты взаимодействуют с системами, собственными в облаке
author: robvet
ms.date: 01/19/2021
ms.openlocfilehash: b28fd05aded652057deecd6814199e0360202a07
ms.sourcegitcommit: 46cfed35d79d70e08c313b9c664c7e76babab39e
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/10/2021
ms.locfileid: "102604519"
---
# <a name="front-end-client-communication"></a>Взаимодействие с внешними клиентами

В собственной облачной системе клиентские клиенты (мобильные, веб-приложения и настольные) должны иметь канал связи для взаимодействия с независимыми микрослужбами.  

Какие варианты существуют?

Для простоты клиент клиентского интерфейса может *напрямую взаимодействовать* с внутренними микрослужбами, как показано на рисунке 4-2.

![Прямой обмен данными между клиентом и службой](./media/direct-client-to-service-communication.png)

**Рис. 4-2.** Прямой обмен данными между клиентом и службой

При таком подходе каждая микрослужба имеет общедоступную конечную точку, доступную клиентам клиентского доступа. В рабочей среде подсистема балансировки нагрузки помещается перед микрослужбами, поэтому трафик передается пропорционально.

Простота взаимодействия с клиентами, хотя и проста в реализации, может быть приемлемым только для простых приложений микрослужб. Этот шаблон тесно связывает клиентские интерфейсы с основными серверными службами, открывая дверцу для ряда проблем, в том числе:

- Уязвимости клиента для рефакторинга серверной службы.
- Более широкая контактная зона в качестве основных серверных служб предоставляется напрямую.
- Дублирование перекрестных проблем в каждой микрослужбе.
- Чрезмерно сложный клиентский код — клиенты должны отследить несколько конечных точек и отреагировать на сбои в устойчивом виде.

Вместо этого широко принятый шаблон проектирования в облаке — реализация [службы шлюза API](../microservices/architect-microservice-container-applications/direct-client-to-microservice-communication-versus-the-api-gateway-pattern.md) между внешними приложениями и серверными службами. Шаблон показан на рисунке 4-3.

![Шаблон шлюза API](./media/api-gateway-pattern.png)

**Рис. 4-3.** Шаблон шлюза API

На предыдущем рисунке обратите внимание на то, как служба шлюза API абстрагирует основные микрослужбы ядра серверной части. Реализованный как веб-API, он выступает в качестве *обратных прокси-серверов* и направляет входящий трафик во внутренние микрослужбы.

Шлюз изолирует клиент от внутреннего секционирования и рефакторинга службы. При изменении серверной службы она размещается в шлюзе без нарушения работы клиента. Это также первая строка обороны для перекрестных задач, таких как идентификация, кэширование, устойчивость, отслеживание и регулирование. Многие из этих проблем могут быть отключены от серверных основных служб до шлюза, что упрощает работу серверных служб.

Необходимо соблюдать осторожность, чтобы упростить и ускорить работу шлюза API. Как правило, Бизнес-логика хранится вне шлюза. Сложные риски шлюза становятся узким местом и в конечном итоге создают сам Монолит. Более крупные системы часто предоставляют несколько шлюзов API, сегментированных по типу клиента (Mobile, Web, Desktop) или серверной функциональности. Шаблон [Серверная часть для внешних интерфейсов](/azure/architecture/patterns/backends-for-frontends) обеспечивает направление реализации нескольких шлюзов. Шаблон показан на рисунке 4-4.

![Серверная часть для внешнего шаблона](./media/backend-for-frontend-pattern.png)

**Рис. 4-4.** Серверная часть для внешнего шаблона

Обратите внимание, что на предыдущем рисунке показано, как входящий трафик отправляется в конкретный шлюз API на основе типа клиента: веб-, мобильного или классического приложения. Этот подход имеет смысл, так как возможности каждого устройства значительно отличаются в пределах форм фактора, производительности и ограничений на отображение. Обычно мобильные приложения предоставляют меньше функциональных возможностей, чем браузер или классические приложения. Каждый шлюз можно оптимизировать в соответствии с возможностями и функциями соответствующего устройства.

Для начала можно создать собственную службу шлюза API. Быстрый поиск в GitHub предоставит множество примеров. Однако доступно несколько платформ и продуктов для коммерческих шлюзов.

## <a name="ocelot-gateway"></a>Шлюз Оцелот

Для простых облачных приложений .NET вы можете использовать [шлюз Оцелот](https://github.com/ThreeMammals/Ocelot). Оцелот — это шлюз API с открытым исходным кодом, созданный для микрослужб .NET, которым требуется единая точка входа в систему. Это упрощенный, быстрый и масштабируемый.

Как и любой другой шлюз API, его основная функциональность заключается в пересылке входящих HTTP-запросов к подчиненным службам. Кроме того, он поддерживает широкий спектр возможностей, которые можно настроить в конвейере по промежуточного слоя .NET. Его набор функций представлен в следующей таблице.

|Функции Оцелот  | |
| :-------- | :-------- |
| Маршрутизация | Аутентификация |
| Агрегирование запросов | Авторизация |
| Обнаружение служб (с помощью Consul и Еурека) | Регулирование |
| Балансировка нагрузки | Ведение журнала, трассировка |
| Caching | Преобразование заголовков/строки запроса |
| Pass-Through корреляции | Настраиваемое по промежуточного слоя |
| Качество обслуживания | Политики повтора |

Каждый шлюз Оцелот определяет вышестоящий и нисходящий адреса и настраиваемые функции в файле конфигурации JSON. Клиент отправляет HTTP-запрос шлюзу Оцелот. После получения Оцелот передает объект HttpRequest через его конвейер, манипулирующий этим объектом, в состояние, заданное его конфигурацией. В конце конвейера Оцелот создает новый Хттпреспонсеобжект и передает его в подчиненную службу. Для ответа Оцелот выполняет обратный конвейер, отправляя ответ обратно клиенту.

Оцелот доступен в виде пакета NuGet. Он предназначен для NET Standard 2,0, что делает его совместимым с .NET Core 2.0 и платформа .NET Framework 4.6.1 + Runtime. Оцелот интегрируется с любым компонентом, который говорит по протоколу HTTP и работает на платформах, поддерживаемых .NET Core: Linux, macOS и Windows. Оцелот является расширяемой и поддерживает многие современные платформы, включая контейнеры DOCKER, службы Kubernetes Azure или другие общедоступные облака.  Оцелот интегрируется с такими пакетами с открытым исходным кодом, как [Consul](https://www.consul.io), [Графкл](https://graphql.org)и [Еурека](https://github.com/Netflix/eureka)Netflix.

Рассмотрим Оцелот для простых облачных приложений, не требующих обширного набора функций для коммерческого шлюза API.

## <a name="azure-application-gateway"></a>Шлюз приложений Azure

Для простых требований к шлюзу вы можете использовать [шлюз приложений Azure](/azure/application-gateway/overview). Доступно в виде [службы Azure PaaS](https://azure.microsoft.com/overview/what-is-paas/), она включает основные функции шлюза, такие как маршрутизация URL-адресов, завершение SSL и брандмауэр веб-приложения. Служба поддерживает возможности [балансировки нагрузки уровня 7](https://www.nginx.com/resources/glossary/layer-7-load-balancing/) . С помощью уровня 7 можно маршрутизировать запросы на основе фактического содержимого HTTP-сообщения, а не только низкого уровня сетевых пакетов TCP.

В этой книге мы пропаганды облачные системы в [Kubernetes](https://www.infoworld.com/article/3268073/what-is-kubernetes-your-next-application-platform.html). Контейнер Orchestrator, Kubernetes автоматизирует развертывание, масштабирование и эксплуатационные проблемы в контейнерных рабочих нагрузках. Шлюз приложений Azure можно настроить в качестве шлюза API для кластера [службы Kubernetes Azure](https://azure.microsoft.com/services/kubernetes-service/) .

Контроллер входящего трафика [шлюза приложений](https://azure.github.io/application-gateway-kubernetes-ingress/) позволяет шлюзу приложений Azure работать непосредственно со [службой Azure Kubernetes](https://azure.microsoft.com/services/kubernetes-service/). На рис. 4,5 показана архитектура.

![Контроллер входящего трафика Шлюза приложений](./media/application-gateway-ingress-controller.png)

**Рис. 4-5.** Контроллер входящего трафика Шлюза приложений

Kubernetes включает встроенную функцию, которая поддерживает балансировку нагрузки HTTP (уровень 7) [, называемую](https://kubernetes.io/docs/concepts/services-networking/ingress/)входящими. Входящий объект определяет набор правил, определяющих, как экземпляры микрослужб внутри AKS могут быть доступны внешнему миру. На предыдущем рисунке контроллер входящего трафика интерпретирует правила входящего трафика, настроенные для кластера, и автоматически настраивает шлюз приложений Azure. На основе этих правил шлюз приложений направляет трафик в микрослужбы, работающие в AKS. Входной контроллер прослушивает изменения в правилах входящих данных и вносит соответствующие изменения в шлюз приложений Azure.

## <a name="azure-api-management"></a>Служба "Управление API Azure"

Для средних и крупномасштабных облачных систем вы можете использовать службу [управления API Azure](https://azure.microsoft.com/services/api-management/). Это облачная служба, которая не только решает ваши потребности в шлюзе API, но и предоставляет полнофункциональную среду разработки и администрирования. Управление API показано на рисунке 4-6.

![Служба "Управление API Azure"](./media/azure-api-management.png)

**Рис. 4-6.** Служба "Управление API Azure"

Для начала служба управления API предоставляет сервер шлюза, который обеспечивает управляемый доступ к внутренним службам на основе настраиваемых правил и политик. Эти службы могут находиться в облаке Azure, в локальном центре обработки данных или в других общедоступных облаках. Ключи API и токены JWT определяют, кто может делать. Весь трафик заносится в журнал для аналитических целей.

Для разработчиков служба управления API предлагает портал разработчика, который предоставляет доступ к службам, документации и примерам кода для их вызова. Разработчики могут использовать API Swagger и Open для проверки конечных точек службы и анализа их использования. Служба работает в основных платформах разработки: .NET, Java, Golang и других.

Портал издателя предоставляет панель мониторинга управления, в которой администраторы предоставляют интерфейсы API и управляют их поведением. Доступ к службе можно предоставить, отслеживать работоспособность службы и собирать данные телеметрии службы. Администраторы применяют *политики* к каждой конечной точке, чтобы влиять на их поведение. [Политики](/azure/api-management/api-management-howto-policies) — это предварительно построенные инструкции, которые последовательно выполняются для каждого вызова службы.  Политики настраиваются для входящего вызова, исходящего вызова или вызова при возникновении ошибки. Политики могут применяться к различным областям служб, что позволяет реализовать детерминированное упорядочение при объединении политик. Продукт поставляется с большим количеством предварительно созданных [политик](/azure/api-management/api-management-policies).

Ниже приведены примеры того, как политики могут повлиять на поведение облачных служб.  

- Ограничьте доступ к службе.
- Принудительная проверка подлинности.  
- При необходимости регулировать вызовы из одного источника.
- Включите кэширование.
- Блокировать вызовы с конкретных IP-адресов.
- Управление потоком службы.
- Преобразование запросов из SOAP в другие форматы данных, например из XML в JSON.

Служба управления API Azure может предоставлять серверные службы, размещенные в любом месте — в облаке или в центре обработки данных. Для устаревших служб, которые могут быть предоставлены в собственных системах в облаке, они поддерживают API-интерфейсы RESTFUL и SOAP. Даже другие службы Azure можно предоставлять через службу управления API. Вы можете разместить управляемый API поверх службы резервного копирования Azure, такой как [служебная шина Azure](https://azure.microsoft.com/services/service-bus/) или [Azure Logic Apps](https://azure.microsoft.com/services/logic-apps/). Служба управления API Azure не включает встроенную поддержку балансировки нагрузки и должна использоваться в сочетании со службой балансировки нагрузки.

Управление API Azure доступно на [четырех разных уровнях](https://azure.microsoft.com/pricing/details/api-management/):

- Разработчик
- Basic
- Standard
- Premium

Уровень разработчика предназначен для непроизводственных рабочих нагрузок и оценки. Другие уровни предлагают более мощные возможности, функции и более высокие соглашения об уровне обслуживания (SLA). Уровень "Премиум" обеспечивает [виртуальную сеть Azure](/azure/virtual-network/virtual-networks-overview) и [поддержку нескольких регионов](/azure/api-management/api-management-howto-deploy-multi-region). Все уровни имеют фиксированную цену за час.

Облако Azure также предлагает [бессерверный уровень](https://azure.microsoft.com/blog/announcing-azure-api-management-for-serverless-architectures/) для управления API Azure. Эта служба, называемая *ценовой категорией потребления*, представляет собой вариант управления API, разработанный на основе бессерверной вычислительной модели. В отличие от ранее показанных ценовых категорий, уровень потребления предоставляет возможность мгновенной подготовки и оплаты за действие.

Он включает функции шлюза API для следующих вариантов использования:

- Микрослужбы, реализованные с использованием бессерверных технологий, таких как [функции Azure](/azure/azure-functions/functions-overview) и [Azure Logic Apps](https://azure.microsoft.com/services/logic-apps/).
- Резервные ресурсы службы Azure, такие как очереди и разделы служебной шины, служба хранилища Azure и другие.
- Микрослужбы, в которых трафик имеет случайные пиковые пики, но остается небольшими.

Уровень потребления использует те же базовые компоненты управления API службы, но использует совершенно другую архитектуру, основанную на динамически выделяемых ресурсах. Он идеально соответствует модели бессерверных вычислений:

- Нет инфраструктуры для управления.
- Нет бездействующей емкости.
- Высокий уровень доступности.
- Автоматическое масштабирование.
- Стоимость зависит от фактического использования.
  
Новая категория потребления — отличный вариант для собственных облачных систем, которые предоставляют бессерверные ресурсы в качестве API-интерфейсов.

## <a name="real-time-communication"></a>связь в режиме реального времени;

Обмен данными в режиме реального времени или Push-уведомления — это еще один вариант для интерфейсных приложений, взаимодействующих с внутренними облачными системами по протоколу HTTP. Такие приложения, как финансовые тикеры, Интернет-учреждения, игры и обновления хода выполнения заданий, занимают мгновенные ответы в режиме реального времени от серверной части. При обычной связи по протоколу HTTP клиенту не удается получить сведения о доступности новых данных. Клиент должен постоянно *опрашивать* или отправлять запросы на сервер. При обмене данными в *режиме реального времени* сервер может в любое время отправлять новые данные клиенту.

Системы в режиме реального времени часто характеризуются потоками данных с высокой частотой и большим числом параллельных клиентских подключений. Ручная реализация подключения в режиме реального времени может быстро стать сложной и требовать нетривиальные инфраструктуры для обеспечения масштабируемости и надежного обмена сообщениями между подключенными клиентами. Вы можете управлять экземпляром кэша Redis для Azure и набором подсистем балансировки нагрузки, настроенных с прикрепленными сеансами для сходства клиентов.

[Служба Azure SignalR](https://azure.microsoft.com/services/signalr-service/) — это полностью управляемая служба Azure, которая упрощает обмен данными в облаке с собственными приложениями в режиме реального времени. Сведения о технической реализации, такие как подготовка ресурсов, масштабирование и постоянные подключения, являются абстрактными. Они обрабатываются с помощью соглашения об уровне обслуживания 99,9%. Вы сосредоточены на функциях приложения, а не на инфраструктуре.

После включения облачная служба HTTP может отправлять обновления содержимого непосредственно подключенным клиентам, включая браузер, мобильные и классические приложения. Клиенты обновляются без необходимости опрашивать сервер. Azure SignalR абстрагирует технологии транспорта, которые создают подключение в режиме реального времени, включая WebSocket, Server-Sideные события и длительный опрос. Разработчики сосредоточены на отправке сообщений всем или конкретным подмножествам подключенных клиентов.

На рис. 4-7 показан набор HTTP-клиентов, подключающихся к облачному приложению с включенным сигнальным приложением Azure SignalR.

![Azure SignalR](./media/azure-signalr-service.png)

**Рис. 4-7**. Azure SignalR

Еще одним преимуществом службы Azure SignalR является реализация безсерверных облачных служб. Возможно, ваш код выполняется по запросу с помощью триггеров функций Azure. Этот сценарий может быть непростым, поскольку код не поддерживает длинные соединения с клиентами. Служба Azure SignalR может справиться с этой ситуацией, так как она автоматически управляет подключениями.

Служба Azure SignalR тесно интегрируется с другими службами Azure, такими как база данных SQL Azure, служебная шина или кэш Redis, что открывает множество возможностей для собственных облачных приложений.

>[!div class="step-by-step"]
>[Назад](communication-patterns.md)
>[Вперед](service-to-service-communication.md)
